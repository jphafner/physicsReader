---
title: Randomness and The Twentieth Century
author: Alfred M. Bork
excerpt: The use of random elements is common today not only in science, but also in music, art, and literature.
    One influence was the success of kinetic theory in the nineteenth century.
intro: An article from <em>The Antioch Review</em>, 1967.
---


As I write this I have in front of me a book that may be unfamiliar to many.
It is entitled One Million Random Digits with 1,000 Normal Deviates and was produced by the Rand Corporation in 1955.
As the title suggests, each page contains digits&emdash;numbers from 1 to 9&emdash;arranged as nearly as possible in a completely random fashion.
An electronic roulette wheel generated the numbers in this book, and afterwards the numbers were made even more random by shuffling and other methods.
There is a careful mathematical definition of randomness, and associated with it are many tests that one can apply.
These numbers were shuffled until they satisfied the tests.
I want to use this book as a beginning theme for this paper.
The production of such a book is entirely of the twentieth century.
It could not have been produced in any other era.
I do not mean to stress that the mechanism for doing it was not available, although that is also true.
What is of more interest is that before the twentieth-century no one would even have thought of the possibility of producing a book like this; no one would have seen any use for it.
A rational nineteenth-century man would have thought it the height of folly to produce a book containing only random numbers.
Yet such a book is important, even though it is not on any of the usual lists of one hundred great books.



That this book is strictly of the twentieth century is in itself of importance.
I claim that it indicates a cardinal feature of our century: randomness, a feature permeating many different and apparently unrelated aspects of our culture.
I do not claim that randomness is the only feature which characterizes and separates twentieth century thought from earlier thought, or even that it is dominant, but I will argue, admittedly on a speculative basis, that it is an important aspect of the twentieth century.


Before I leave the book referred to above, you may be curious to know why a collection of random numbers is of any use.
The Rand Corporation, a government-financed organization, is not likely to spend its money on pursuits having no possible application.
The principal use today of a table of random numbers is in a calculational method commonly used on large digital computers.
Because of its use of random numbers, it is called the Monte Carlo method, and it was developed primarily by Fermi, von Neumann, and Ulam at the end of the Second World War.
The basic idea of the Monte Carlo method is to replace an exact problem which cannot be solved with a probabilistic one which can be approximated.
Another area where a table of random numbers is of importance is in designing experiments, particularly those involving sampling.
If one wants, for example, to investigate certain properties of wheat grown in a field, then one wants thoroughly random samplings of wheat; if all the samples came from one corner of the field, the properties found might be peculiar to that corner rather than to the whole field.
Random sampling is critical in a wide variety of situations.


Actually, few computer calculations today use a table of random numbers; rather, a procedure suggested during the early days of computer development by John von Neumann is usually followed.
Von Neumann&#39;s idea was to have the computer generate its own random numbers.
In a sense numbers generated in this way are not &ldquo;random,&rdquo; but they can be made to satisfy the same exacting tests applied to the Rand Table; randomness is a matter of degree.
It is more generally convenient to let the computer produce random numbers than to store in the computer memory a table such as the Rand Table.
Individual computer centers often have their own methods for generating random numbers.


I shall not give any careful definition of randomness, but shall rely on intuitive ideas of the term.
A formal careful definition would be at odds with our purposes, since, as A. O. Lovejoy noted in <em>The Great Chain of Being</em>, it is the vagueness of the terms which allows them to have a life of their own in a number of different areas.
The careful reader will notice the shifting meanings of the word &ldquo;random,&rdquo; and of related words, in our material.


However, it may be useful to note some of the different ideas connected with randomness.
D. M. Mackay, for example, distinguishes between &ldquo;(a) the notion of well-shuffledness or impartiality of distribution;
    (b) the notion of irrelevance or absence of correlation;
    (c) the notion of `I don&#39;t care&#39;;
    and (d) the notion of chaos&rdquo;
\footnote{
    Donald M. Mackay, &ldquo;Theoretical Models of Space Perception&emdash;Appendix,&rdquo;
    in &ldquo;Aspects of the Theory of Artificial Intelligence,&rdquo;
    <em>The Proceedings of the First International Symposium of Biosimulation</em>,
    edited by C. A. Muses (Plenium Press, New York, 1962), p. 240.
}
Although this is not a complete, mutually exclusive classification&emdash;the editor of the volume in which it appears objects to it&emdash;the classification indicates the range of meaning that &ldquo;random&rdquo; has even in well-structured areas like information theory.


Let us, then, review the evidence of randomness in several areas of twentieth-century work, and then speculate on why this concept has become so pervasive, as compared with the limited use of randomness in the nineteenth century.


I begin with the evidence for randomness in twentieth-century physics.
There is no need to search far, for the concept helps to separate our physics from the Newtonian physics of the last few centuries.
Several events early in this century made randomness prominent in physics.
The first was the explanation of Brownian motion.
Brownian movement, the microscopically observed motion of small suspended particles in a liquid, had been known since the early 1800&#39;s.
A variety of explanations had been proposed, all unsatisfactory.
But Albert Einstein showed, in one of his three famous papers of 1905, that Brownian motion could be understood in terms of kinetic theory:


<blockquote>
    &hellip; it will be shown that according to the molecular-kinetic theory of heat, bodies of microscopically visible size, suspended in a liquid, will perform movements of such magnitude that they can be easily observed in a microscope on account of the molecular motions of heat.
    It is possible that the movements to be discussed here are identical with the so-called &ldquo;Brownian molecular motion.&rdquo;
    &hellip; if the movement discussed here can actually be observed &hellip; then classical thermodynamics can no longer be looked on as applicable with precision to bodies even of dimensions distinguishable in a microscope
    &hellip; On the other hand [if] the prediction of this movement proves to be incorrect, weighty argument would be provided against the molecular-kinetic theory of heat.
\footnote{
    Albert Einstein, <em>Investigations on the Theory of Brownian Movement</em>,
    edited by R. F&uuml;rth, translated by A. A, Cowper (E. P. Dutton, New York).
}
</blockquote>

It is the randomness of the process, often described as a &ldquo;random
walk,&rdquo; which is the characteristic feature of Brownian motion.

But an even more direct experimental situation focused attention on randomness.
During the last years of the nineteenth century, physicists suddenly found many new and strange &ldquo;rays&rdquo; or &ldquo;radiations,&rdquo; including those from radioactive substances.
A series of experimental studies on alpha-rays from radioactive elements led Rutherford to say in 1912 that &ldquo;The agreement between theory and experiment is excellent and indicates that the alpha particles are emitted at random and the variations accord with the laws of probability.&rdquo;
\footnote{
    E. Rutherford, <em>Radioactive Substances and their Radiations</em>
    (Cambridge University Press, Cambridge. 1913), p. 191.
}
These radiations were associated with the core of the atom, the nucleus, so randomness was present in the heart of matter.


One of the two principal physical theories developed in the past forty years is the theory of atomic structure, quantum mechanics, developed during the period from 1926 to 1930.
Wave mechanics, the form of quantum mechanics suggested by the Austrian physicist Erwin Schrodinger, predicted in its original form only the allowable energy levels and hence the spectroscopic lines for an atom of some particular element.
Later, Max Born and Werner Heisenberg gave quantum theory a more extensive interpretation, today called the &ldquo;Copenhagen Interpretation,&rdquo; which relinquishes the possibility of predicting exactly the outcome of an individual measurement of an atomic (or molecular) system.
Instead, statistical predictions tell what, on the average, will happen if the same measurement is performed on a large number of identically prepared systems.
Identical measurements on identically prepared systems, in this view, do not always give the same result. Statistical ideas had been used in the nineteenth-century physics, but then it was always assumed that the basic laws were completely deterministic.
Statistical calculations were made when one lacked complete information or because of the complexity of the system involved.
In the statistical interpretation of quantum mechanics I have just described, however, randomness is not accepted purely for calculational purposes.
It is a fundamental aspect of the basic physical laws themselves.
Although some physicists have resisted this randomness in atomic physics, it is very commonly maintained.
A famous principle in contemporary quantum mechanics, the &ldquo;uncertainty principle,&rdquo; is closely related to this statistical view of the laws governing atomic systems.


These examples illustrate randomness in physics; now we proceed to other areas.
Randomness in art is particularly easy to discuss because it has been so consistently and tenaciously used.
My first example is from graphic design.
For hundreds of years books and other publications have been &ldquo;justified&rdquo; in the margins in order to have flush right margins in addition to flush left margins.
This is done by hyphenation and by adding small spaces between letters and words.
But recently there is a tendency toward books that are not &ldquo;justified&rdquo;; the right margins end just where they naturally end, with no attempt to make them even.
This is a conscious design choice. Its effect in books with two columns of print is to randomize partially the white space between columns of print, instead of maintaining the usual constant width white strip.


In the fine arts, the random component of assemblages, such as those of Jean Tinguely, often lies in the use of &ldquo;junk&rdquo; in their composition.
The automobile junkyard has proved to be a particularly fruitful source of material, and there is something of a random selection there.
Random modes of organization, such as the scrapmetal press, have also been used.


In art, as elsewhere, one can sometimes distinguish two kinds of randomness, one involving the creative technique and another exploiting the aesthetic effects of randomness.
We see examples of this second type, called &ldquo;accident as a compositional principle&rdquo; by Rudolf Arnheim, in three woodcuts by Jean Arp, entitled &ldquo;Placed According to the Laws of Chance.&rdquo;
We would perhaps not have understood the artist&#39;s intent if we did not have the titles.
Arp, like other contemporary artists, has returned repeatedly to the exploration of such random arrangements.
As James Thrall Soby says, &ldquo;There can be no doubt that the occasional miracles of accident have particular meaning for him. . . . One assumes that he considers spontaneity a primary asset of art.&rdquo;
\footnote{
    James Thrall Soby, <em>Arp</em> (Museum of Modern Art, New York, 1958).
}


An area which has been particularly responsive to the exploration of randomness for aesthetic purposes is &ldquo;op art.&rdquo;
Again the titles often identify this concept, as in &ldquo;Random Field&rdquo; by Wen-Yin Tsai.


Perhaps more common, however, is the former aspect, an artistic technique by which the artist intentionally employs some random element.
The contemporary school of action painting is an example.
Jackson Pollock often would place his canvas on the ground and walk above it allowing the paint to fall several feet from his brush to the canvas.
Soby describes it as follows: &ldquo;Pollock&#39;s detractors call his current painting the &#39;drip&#39; or &#39;spatter&#39; school, and it is true that he often spreads large canvases on the floor and at them flings or dribbles raw pigments of various colors.&rdquo;
\footnote{
    James Thrall Soby, &ldquo;Jackson Pollock,&rdquo;
    in The New Art in America (Frederick Praeger, Inc., Greenwich, Conn., 1957).
}
With this method he did not have complete control of just where an individual bit of paint fell&emdash;this depended in a complicated way on the position of the brush, the velocity of the brush, and the consistency of the paint.
Thus this technique had explicit chance elements, and its results have been compared to Brownian motion.


Similarly, J. R, Rierce, in Symbols, Signals, and Noise, discussing random elements in art, gives some examples of computer-generated art.
He emphasizes the interplay of &ldquo;both randomness and order&rdquo; in art, using the kaleidoscope as an example.


I will comment even more briefly on music.
In Percy Granger&#39;s &ldquo;Random Round&rdquo; each instrument has a given theme to play; the entrances are in sequence, but each player decides for himself just when he will enter.
Thus each performance is a unique event, involving random choices.
The most famous example of random musical composition is the work of John Cage.
One of his best known works involves a group of radios on a stage, each with a person manipulating the controls.
They work independently, each altering things as he wishes, and the particular performance is further heavily dependent on what programs happen to be playing on the local radio stations at the time of the performance.
There is no question that Cage furnishes the most extreme example of exploitation of techniques with a chance component.


Most evidence for randomness in literature is not as clear as in science, art, or music.
The first example is clear, but perhaps some will not want to call it literature at all.
In 1965 two senior students at Reed College saw some examples of computer-produced poetry and decided that they could do as well.
As their model was symbolist poetry, they did not attempt rhyme or meter, although their program might be extended to cover either or both.
The computer program is so organized that the resulting poem is based on a series of random choices.
First, the computer chooses randomly a category&emdash;possibilities are such themes as &ldquo;sea&rdquo; or &ldquo;rocks.&rdquo;
The program then selects (again using a built-in random number generator) a sentence structure from among twenty possibilities.
The sentence structure contains a series of parts of speech.
The computer randomly puts words into it, keeping within the previously chosen vocabulary stored in the computer memory.
Because of the limited memory capacity of the small computer available, only five words occur in a given thematic and grammatical category.
There are occasionally some interesting products.


Turning from a student effort to a recently available commercial product, consider the novel Composition I by Marc Saporta, which comes in a box containing a large number of separate sheets.
Each page concludes with the end of a paragraph.
The reader is told to shuffle the pages before beginning to read.
Almost no two readers will see the pages in the same order, and the ordering is determined in a random process.
For some readers the girl is seduced before she is married, for other readers after she is married.
A similar process has been used by William Burroughs in The Naked Lunch and elsewhere, except that in this case the shuffling is done by the writer himself.
Burroughs writes on many separate pieces of paper and then orders them over and over in different ways until he is satisfied with the arrangement.
He has suggested that his work can be read in other orders, and ends <em>The Naked Lunch</em> with an &ldquo;Atrophied Preface.&rdquo;


P. Mayersburg
\footnote{
    P. Mayersberg, &ldquo;The Writer as Spaceman,&rdquo; The Listener, October 17, 1963, p. 607.
}
has pointed out elements of chance construction in several other writers&#39; work.
He says of Michel Botor: &rdquo;Mobile is constructed around coincidence: coincidence of names, places, signs, and sounds &hellip; Coincidence implies the destruction of traditional chronology.
It replaces a pattern of cause and effect with one of chance and accident.&rdquo;
He sees another chance aspect in these writers: they recognize that they cannot completely control the mind of the reader.


But can we find examples in the work of more important writers?
The evidence is less direct.
While contemporary artists have openly mentioned their use of randomness, contemporary writers and critics, with a few exceptions, have seldom been willing to admit publicly that randomness plays any role in their writings.
But I will argue that randomness is nevertheless often there, although I am aware of the difficulty of establishing it firmly.


The cubist poets, perhaps because of their associations with artists, did experiment consciously with randomness.
The story is told of how Apollinaire removed all the punctuation from the proofs of <em>Alcools</em> because of typesetting errors, and he continued to use random organization in his &ldquo;conversation poems&rdquo; and in other work.


<blockquote>
    The &ldquo;opposite of narration&rdquo; defines the very quality Apollinaire finally grasped in following cubism into the experimental work of Delaunay, the quality he named simultanism.
    It represents an effort to retain a moment of experience without sacrificing its logically unrelated variety.
    In poetry it also means an effort to neutralize the passage of time involved in the act of reading.
    The fragments of a poem are deliberately kept in a random order to be reassembled in a single instant of consciousness.&#39;
\footnote{
    Roger Shattuck, <em>The Banquet Years</em> (Harcourt, Brace, and Co., New York), p. 238.
}
</blockquote>


It can be argued that James Joyce used random elements in <em>Ulysses</em> and <em>Finnegans Wake</em>.
Several minor stories at least indicate that Joyce was not unfriendly toward the use of random input.
For example, when Joyce was dictating to Samuel Beckett, there was a knock at the door.
Joyce said, &ldquo;Come in,&rdquo; and Beckett wrote down, &ldquo;Come in,&rdquo; thinking that it was part of the book.
He inmiediatcly realized that Joyce had not intended to dictate it; but when he started to erase it, Joyce insisted that it should stay.
And it is still there in Finnegans Wake, because of a chance occurrence.
A related comment is made by Budgin in James Joyce and the Maying of Ulysses: &ldquo;&hellip; he was a great believer in his luck.
What he needed would come to him.&rdquo;


Proceeding from such stories to Joyce&#39;s books, I believe that there are random elements in the vocabulary itself.
It is well known that much of the vocabulary of Finnegans Wake differs from the vocabulary of other English-language books.
Some of the words are combinations of other better-known English words, and others are traceable to exotic sources. I do not think that Joyce constructed every new word carefully, but rather that he consciously explored randomly or partially randomly formed words.
There is some slight tradition for this procedure in such works as &ldquo;Jabberwocky.&rdquo;


Another aspect of Joyce&#39;s writing, shared with other works of contemporary literature, also has some connection with our theme, although this connection is not generally realized.
I refer to the &ldquo;stream of consciousness&rdquo; organization.
The Victorian novel was ordered in a linear time sequence; there were occasional flashbacks, but mostly the ordering of events in the novel was chronological.
The stream of consciousness novel does not follow such an order, but instead the events are ordered as they might be in the mind of an individual.
This psychological ordering has distinctly random elements.
Finnegans Wake has been interpreted as one night in the mental life of an individual.
I would not claim that our conscious processes are completely random, but I think it is not impossible to see some random elements in them


We mentioned that it has not been customary to admit that randomness is a factor in contemporary literature.
Much of the critical literature concerning Joyce exemplifies this.
But at least one study sees Joyce as using random components: R. M. Adams&#39; <em>Surface and Symbol&emdash;the Consistency of James Joyce&#39;s Ulysses</em>.
\footnote{
    R. M. Adams, <em>Surface and Symbol&emdash;The Consistency of James Joyce&#39;s Ulysses</em> (Oxford University Press, New York, 1952).
}
Adams relates the story of the &ldquo;come in&rdquo; in Finnegans Wake, and he tells of Joyce&#39;s requesting &ldquo;any God dam drivel you may remember&rdquo; of his aunt.
Adams points out that artists and musicians of the period were also using chance components: &ldquo;Bits of rope, match or newspaper began to be attached to paintings, holes were cut in their surfaces, toilet bowls and spark plugs appeared unadorned on pedestals as works of original sculpture&hellip; &rdquo; Adams calls Ulysses a collage, and in his conclusion he cautions against trying to define the symbolism of every tiny detail in <em>Ulysses</em>:
&ldquo;The novel is, in part at least, a gambler&#39;s act of throwing his whole personality&emdash;his accidents, his skills, his weaknesses, his luck&emdash;against the world.&rdquo;


My final example of randomness is lighter.
I am reliably informed that several years ago a group of students at Harvard formed a random number society for propagating interest in random numbers.
Among other activities they chose each week a random number of the week, and persuaded a local radio station to announce it!




Although the reader may not accept my thesis, I continue with the assumption that our culture differs from the culture of the previous few centuries partly because of an increased concern with and conscious use of elements which are random in some sense of the word.
We have seen this use in seemingly unrelated areas, and in ways previously very uncommon.
Now we will enter on an even more difficult problem: assuming that the twentieth century consciously seeks out randomness, can we find any historical reasons for its permeating different fields?


I need hardly remind you of the difficulty of this problem.
Theorizing in history has generally seemed unreasonable, except to the theorist himself and to a small group of devoted followers.
The present problem is not general history but the even more difficult area of intellectual history.
Despite vigorous attempts to understand cultural evolution, or particular aspects of it such as the development of scientific knowledge, I believe it is fair to say that we know far less than we would like to know about how ideas develop.
It would, therefore, be unreasonable for me to expect to give a rich theory of how humans modify ideas.
Instead I shall grope toward a small piece of such a theory, basing my attempt on the evidence presented on randomness as a twentieth-century theme.


The rough idea I shall bring to your attention might be crudely called the &ldquo;splash in the puddle&rdquo; theory.
If a stone is dropped in a pond, waves travel out from the disturbance in all directions; a big splash may rock small boats a good bit away from the initial point of impact.
Without claiming that this &ldquo;mechanism&rdquo; is complete, I shall argue that cultural evolution bears some analogy to the splash in the puddle.
Even though the nineteenth century rejected the theme of fundamental randomness, cultural events then created new waves of interest in randomness, which eventually, through the traveling of the wave, affected areas at a distance from the source.
Probably one source is not enough; often one needs reinforcement from several disturbances to create a revolution.
And the sources themselves must be powerful if the effects are to be felt at great distances in the cultural plane.


I shall note two nineteenth-century events which were powerful sources, and so may have contributed to a new interest in randomness.
Both are from science, but this may reflect my own specialization in history of science; I am likely to find examples from the area I know best.
My two examples are of unequal weight.
The minor one certainly affected profoundly the physicist&#39;s attitude toward randomness, but how widespread its effect was is not clear.
The second example, however, was the major intellectual event of the century.


The first example is the development of kinetic theory and statistical thermodynamics in the last half of the century, involving Rudolf Clausius, James Clerk Maxwell, Ludwig Boltzmann, Willard Gibbs, and others.
Because physicists believed that Newtonian mechanics was the fundamental theory, they thought that all other theories should &ldquo;reduce&rdquo; to it, in the same sense that all terms could be defined using only the terms of mechanics, and that the fundamental principles of other areas could be deduced logically from the principles of mechanics.
This attitude, applied to thermodynamics, led to kinetic theory and statistical thermodynamics.


In kinetic theory a gas (a word which may originally have meant &ldquo;chaos&rdquo;
\footnote{
    Pointed out to me by Steven Brush. See J. R. Partington, &ldquo;Joan Baptist von Helmont,&rdquo; Annals of Science, I, 359&endash;384 (1936)
   
}
) was viewed as a very large number of separate particles, each obeying the Newtonian laws of motion, exerting forces on each other and on the walls of the container.
To know the positions and velocities of all the particles was impossible because of the multitude of particles; ordinary quantities of gas contained \num{e24}&emdash;one followed by twenty-four zeros&emdash;particles.
This lack of complete information made it necessary to use general properties such as energy conservation in connection with probability considerations.
One could not predict where each particle would be, but one could predict average behavior and relate this behavior to observed thermodynamical quantities.
Thus statistical thermodynamics introduced statistical modes of thought to the physicist; but the underlying laws were still considered to be deterministic.


A fundamental quantity in thermodynamics, entropy, was found to have a simple statistical interpretation: it was the measure of the degree of randomness in a collection of particles.
Entropy could be used as the basis of the most elegant formulation of the second law of thermodynamics: in a closed system the entropy always increases, or the degree of randomness tends to increase.


A special series of technical problems developed over the two kinds of averaging used in statistical considerations: time-averaging, inherently involved in all measurements; and averaging over many different systems, the ensemble averaging of Gibbs used in the calculations.
The &ldquo;ergodic theorems&rdquo; that were extensively developed to show that these two averages were the same again forced careful and repeated attention on probabilistic considerations.


My second example is the theory of evolution, almost universally acknowledged as the major intellectual event of the last century.
Charles Darwin and Alfred Russell Wallace developed the theory Independently, using clues from Malthus&#39; essay on population.
The basic ideas are well known. Organisms vary, organisms having the fittest variations survive, and these successful variations are passed on to the progeny.
The random element of evolution is in the &ldquo;numerous successive, slight favorable variations&rdquo;; the offspring differ slightly from the parents.
Darwin, lacking an acceptable theory of heredity, had little conception of how these variations come about; he tended to believe, parallel to the developers of statistical thermodynamics, that there were exact laws, but that they were unknown.


<blockquote>
I have hitherto sometimes spoken as if the variations &hellip; had been due to chance.
This, of course, is a wholly incorrect expression, but it seems to acknowledge plainly our ignorance of the cause of each particular variation.
\footnote{
    C. Darwin, <em>Origin of the Species</em> (first edition), p. 114.
}
</blockquote>


But Others were particularly disturbed by the chance factors apparently at work in variations.
This was one of the factors that led Samuel Butler from his initial praise to a later critical view of Darwin. Sir John Herschel was very emphatic:


We can no more accept the principle of arbitrary and casual variation and natural selection as a sufficient account, per se, of the past and present organic world, than we can receive the Laputian method of composing books &hellip; as a sufficient one of Shakespeare and the Principia
\footnote{
    Sir Herschel, <em>Physical Geography of the Globe</em> (Edinburgh, 1861), quoted in John C. Green, The Death of Adam (New American Library, New York), p. 296.
}
When a usable theory of heredity was developed during the next half century, randomness played a major role, both in the occurrence of mutations in genes and in the genetic inheritance of the offspring.
So, almost in spite of Darwin, chance became increasingly important in evolutionary theory. &ldquo;
&hellip; The law that makes and loses fortunes at Monte Carlo is the same as that of Evolution.&rdquo;
\footnote{
    M. Hopkins, <em>Chance and Error&emdash;The Theory of Evolution</em> (Kegan Paul, Trench, Truber \& Co., London, 1923).
}


The theory of evolution roused almost every thinking man in the late nineteenth century.
Frederick Pollock, writing about the important British mathematician William Kingdon Clifford, says:


<blockquote>
    For two or three years the knot of Cambridge friends of whom Clifford was a leading spirit were carried away by a wave of Darwinian enthusiasm:
        we seemed to ride triumphant on an ocean of new life and boundless possibilities.
    Natural selection was to be the master-key of the universe;
        we expected it to solve all riddles and reconcile all contradictions.
\footnote{
    W. K. Clifford, <em>Lectures and Essays</em> (Macmillan, London, 1886), Introduction.
   
}
</blockquote>


This is only one account outside biology, but it illustrates how evolution affected even those not directly concerned with it as a scientific theory.
It does not seem unreasonable, then, that at the same time evolution contributed to the new attitude toward randomness.
I might also mention two other books that are particularly interesting in showing the influence of evolution outside the sciences, offering details we cannot reproduce here.
One is Leo J. Henkin&#39;s <em>Darwinism in the English Novel 1860&endash;1920</em>; the other is Alvar Elleg\^{a}rd&#39;s <em>Darwin and the General Reader</em>.


There were of course other things happening in the nineteenth century, but these two developments were important and had far-reaching implications outside of their immediate areas.
Alfred North Whitehead, in <em>Science and the Modern World</em>, claims that in the nineteenth century &ldquo;four great novel ideas were introduced into theoretical science.&rdquo;
Two of these ideas were energy, whose rise in importance was related to thermodynamics, and evolution.
It was consistent with established tradition, however, to believe that the use of chance in these areas was not essential.
Other non-scientific factors were also important; for example.
Lord Kelvin&#39;s attitude toward chance was colored by religious considerations.
In S. P.  Thomson&#39;s <em>Life</em> we find a speech of his in the Times of 1903 arguing that &ldquo;There is nothing between absolute scientific belief in Creative Power and the acceptance of the theory of a fortuitous concourse of atoms.&rdquo;



According to our splash in the puddle theory, we should be able to point out evidence that two nineteenth-century developments, statistical mechanics and evolution, had very far-reaching effects in areas quite different from their points of origin, effects reflecting interest in randomness.
This is a big task, but we will attempt to give some minimal evidence by looking at the writings of two important American intellectuals near the turn of the century, both of whom were consciously influenced by statistical mechanics and Darwinian evolution.
The two are Henry Adams and Charles Sanders Peirce.


We have Adams&#39; account of his development in <em>The Education of Henry Adams</em>.
Even a casual glance shows how much of the language of physics and biology occurs in the book, and how often references are made to those areas.
Chapter 15 is entitled &ldquo;Darwinism,&rdquo; and early in the chapter he says:

<blockquote>
    The atomic theory; the correlation and conservation of energy;
        the mechanical theory of the universe; the kinetic theory of gases;
        and Darwin&#39;s law of natural selection were examples of what a young man had to take on trust.
</blockquote>


Adams had to accept these because he was not in a position to argue against them.
Somewhat later in the book Adams comments, in his usual third person:

<blockquote>
    He was led to think that the final synthesis of science and its ultimate triumph was the kinetic theory of gases.
    &hellip; so far as he understood it, the theory asserted that any portion of space is occupied by molecules of gas, flying in right lines at velocities varying up to a mile a second, and colliding with each other at intervals varying up to seventeen million seven hundred and fifty thousand times a second.
    To this analysis&emdash;if one understood it right&emdash;all matter whatever was reducible and the only difference of opinion in science regarded the doubt whether a still deeper analysis would reduce the atom of gas to pure motion.
</blockquote>

And a few pages later, commenting on Karl Pearson&#39;s &ldquo;Grammar of Science&rdquo;:

<blockquote>
The kinetic theory of gases is an assertion of ultimate chaos. In plain,
chaos was the law of nature; order was the dream of man.
</blockquote>

Later, &ldquo;Chaos was a primary fact even in Paris,&rdquo; this in reference to Henri Poincare&#39;s position that all knowledge involves conventional elements.

Of all Henry Adams&#39; writings, &ldquo;A Letter to American Teachers of History&rdquo; is most consistently saturated with thermodynamical ideas.
This 1910 paper
\footnote{
    Henry Adams, <em>The Degradation of the Democratic Dogma</em> (Macmillan and Co., New York, 1920), pp. 137-366.
}
begins with thermodynamics.
It first mentions the mechanical theory of the universe, and then says:

<blockquote>
    Toward the middle of the Nineteenth Century&emdash;that is, about 1850&emdash;a new school of physicists appeared in Europe &hellip; made famous by the names of William Thomson, Lord Kelvin, in England, and of Clausius and Helmhokz in Germany, who announced a second law of thermodynamics.
</blockquote>

He quotes the second law of thermodynamics in both the Thomson and the Clausius forms.
It is not always clear how seriously one is to take this thermodynamical model of history.


About fifteen pages into &ldquo;A Letter,&rdquo; Darwin is presented as contradicting the thermodynamical ideas of Thomson.
He sees Darwin&#39;s contribution not in the theory of natural selection, but in that the evolutionary method shows how to bring &ldquo;all vital processes under the law of development.&rdquo;
It is this that is to furnish a lesson to the study of history.
This apparent conflict is one of the major subjects of the early part of the &ldquo;Letter.&rdquo;


<blockquote>
    Thus, at the same moment, three contradictory ideas of energy were in force, all equally useful to science:
    \begin{enumerate}
        \item The Law of Conservation
        \item The Law of Dissipation
        \item The Law of Evolution
    \end{enumerate}
</blockquote>


The contrast Adams is making is between Darwin&#39;s ideas and Kelvin&#39;s ideas.


We find other similar references in Henry Adams, but this should be enough to show his interest in Darwin and kinetic theory.
Other aspects of contemporary science also very much influenced him; he often refers to the enormous change produced by the discovery of new kinds of radiation at the turn of the century.
He seems to be a particularly rewarding individual to study for an understanding of the intellectual currents at the beginning of the century, as Harold G. Cassidy has pointed out:


<blockquote>
    Henry Adams was an epitome of the non-scientist faced with science that he could not understand, and deeply disturbed by the technological changes of the time.
    He was a man with leisure, with the wealth to travel.
    With his enquiring mind he sensed, and with his eyes he saw a great ferment at work in the World.
    He called it a force, and tried to weigh it along with the other forces that moved mankind.
    The education he had received left him inadequate from a technical point of view to understand, much less cope with, these new forces.
    Yet his insights were often remarkable ones, and instructive to us who look at our own period from so close at hand.
\footnote{
    Harold G. Cassidy. "The Muse and the Axiom," American Scientist 51, 315 (1963).
}
</blockquote>

As final evidence we consider the work of the seminal American philosopher Charles Sanders Peirce.
Peirce, although seldom holding an academic position, played an important role in American philosophy, particularly in the development of pragmatism.
He was the leader of the informal &ldquo;Metaphysical Club&rdquo; in Cambridge during the last decades of the century.
The history and views of the group, much influenced by evolutionary ideas, are discussed by Philip Weiner in <em>Evolution and the Founders of Pragmatism</em>.


Peirce was familiar with the development of both statistical thermodynamics and evolution, and both played an enormous role in the development of his thought.
Peirce was a scientist by occupation, so his active interest in science is not surprising.
We find his awareness of these theories (some of which he did not fully accept) evidenced by many passages in his work, such as these comments in &ldquo;On the Fixation of Belief&rdquo;:


<blockquote>
Mr. Darwin has purposed to apply the statistical method to biology.
The same thing has been done in a widely different branch of science, the theory of gases.
We are unable to say what the movements of any particular molecule of gas would be on a certain hypothesis concerning the constitution of this class of bodies.
Clausius and Maxwell were yet able, eight years before the publication of Darwin&#39;s immortal work, by the application of the doctrine of probabilities, to predict that in the long run such and such a proportion of the molecules would under given circumstances, acquire such and such velocities; that there would take place, every second, such and such a relative number of collisions, etc., and from these propositions were able to deduce certain properties of gases especially in regard to the heat relations.
In like manner, Darwin, while unable to say what the operation of variation and natural selection in any individual case will be, demonstrates that, in the long run, they will, or would, adopt animals to their circumstances.
\footnote{
    C. S. Peirce, <em>Collected Papers</em> ed. C. Hartshorn and P. Weiss (Harvard University Press, Cambridge, Mass.). References are to section numbers.
}[5.362]
</blockquote>

A second example in which Peirce links the two theories is in &ldquo;Evolutionary Lore&rdquo;:


<blockquote>
    The Origin of the Species was published toward the end of the year 1859.
    The preceding years since 1846 had been one of the most productive seasons&emdash;or if extended so as to cover the book we are considering, the most productive period in the history of science from its beginnings until now.
    The idea that chance begets order, which is one of the cornerstones of modern physics &hellip; was at that time put into its clearest light. [6.297]
</blockquote>


He goes on to mention Quetelet and Buckle, and then begins a discussion of the kinetic theory:


<blockquote>
Meanwhile, the statistical method had, under that very name, been applied with brilliant success to molecular physics.
&hellip; In the very summer preceding Darwin&#39;s publication, Maxwell had read before the British Association the first and most important of his researches on the subject.
The consequence was that the idea that fortuitous events may result in physical law and further that this is the way in which these laws which appear to conflict with the principle of conservation of energy are to be explained had taken a strong hold upon the minds of all who are abreast of the leaders of thought. [6.297]
</blockquote>


Peirce is not reflecting the historical attitude of the physicists who developed statistical thermodynamics but is reading his own views back into this work.


So it is not surprising that chance plays a fundamental role in Peirce&#39;s metaphysics.
Peirce generalized these ideas into a general philosophy of three categories, Firstness, Secondness, and Thirdness.
These three terms have various meanings in his work, but a frequent meaning of Firstness is chance.
He was one of the first to emphasize that chance was not merely for mathematical convenience but was fundamental to the universe.
He used the word &ldquo;Tychism,&rdquo; from the Greek for &ldquo;chance,&rdquo; the &ldquo;doctrine that absolute chance is a factor in the universe.&rdquo; [6.2000]


This view of the essential role of chance he opposed to the view that universal necessity determined everything by fixed mechanical laws, in which most philosophers of science in the late nineteenth century still believed.
In a long debate between Peirce and Carus concerning this issue, Peirce says:

<blockquote>
    The first and most fundamental element that we have to assume is a Freedom, or Chance, or Spontaneity, by virtue of which the general vague nothing-in-particuiar-ness that preceded the chaos took on a thousand definite qualities.
</blockquote>


In &ldquo;The Doctrine of Necessity&rdquo; Peirce stages a small debate between a believer in his position and a believer in necessity, to show that the usual arguments for absolute law are weak.
Everyday experiences make the presence of chance in the universe almost obvious:


<blockquote>
The endless variety in the world has not been created by law.
It is not of the nature of uniformity to originate variation nor of law to beget circumstance. When we gaze on the multifariousness of nature we arc looking straight into the face of a living spontaneity.
A day&#39;s ramble in the country ought to bring this home to us. [6.553!

A man in China bought a cow and three days and five minutes later a Greenlander sneezed.
Is that abstract circumstance connected with any regularity whatever?
And are not such relations infinitely more frequent than those which are regular? [5.342]
</blockquote>


The necessity of initial conditions in solving the equations of mechanics is another indication to Peirce of the essential part played by chance.
Modern scientists have also stressed the &ldquo;randomness&rdquo; of initial conditions: E. P. Wigner writes, &ldquo;There are &hellip; aspects of the world concerning which we do not believe in the existence of any accurate regularities.
We call these initial conditions.&rdquo;


Peirce tells us we must remember that &ldquo;Three elements are active in the world: first, chance; second, law; and third, habit taking.&rdquo; [1409]
He imagines what a completely chance world would be like, and comments, &ldquo;Certainly nothing could be imagined more systematic.&rdquo;
For Peirce the universe begins as a state of complete randomness.
The interesting problem is to account for the regularity in the universe; law must evolve out of chaos.
This evolutionary process is far from complete even now, and presents a continuing process still:


<blockquote>
    We are brought, then, to this: Conformity to law exists only within a limited range of events and even there is not perfect, for an element of pure spontaneity or lawless originality mingles, or at least must be supposed to mingle, with law everywhere. [1.407]
</blockquote>


Thus Peirce&#39;s scheme starts with chaos and out of this by habit orderliness comes, but only as a partial state.


What is of interest to us is the fundamental role of chance or randomness in Peirce&#39;s cosmology, and the connection of that role with statistical mechanics and Darwinism, rather than the details of his metaphysics.


The two examples of Henry Adams and C. S. Peirce do not establish the splash in the puddle, but they do serve at least to indicate the influence of the Darwinian and kinetic theory ideas, and they show the rising importance of chance.




Although I have concentrated on the relatively increased attention focused upon randomness in the twentieth century as compared with the nineteenth century, randomness attracted some interest before our century.
One can find many earlier examples of the orderrandomness dichotomy, and there have been periods when, even before the nineteenth century, random concepts acquired some status.
One example containing elements of our present dichotomy is the continuing battle between classicism and romanticism in the arts and in literature. But the twentieth-century interest, as we have indicated, is more intense and of different quality.
The chance component has never been totally absent; even the most careful artist in the last century could not be precisely sure of the result of his meticulously controlled brush stroke.
The classical painter resisted chance&emdash;the goal of his years of training was to gain ever greater control over the brush. By contrast the contemporary painter often welcomes this random element and may even increase it.
It is this contrast that I intend to stress. Although I point to this one element, the reader should not falsely conclude that I am not aware of non-random elements.
Even now randomness is seldom the sole factor.
When Pollock painted, the random component was far from the only element in his technique.
He chose the colors, he chose his hand motions, and he chose the place on the canvas where he wanted to work. Further, he could, and often did, reject the total product at any time and begin over.
Except in the most extreme examples, randomness is not used alone anywhere;
    it is almost always part of a larger situation.
This is J. R. Pierce&#39;s emphasis on order.


The persistence of chance elements in highly ordered societies suggests a human need for these elements.
Perhaps no society ever described was more completely organized than Arthur C. Clarke&#39;s fictional city of Diaspar, described in <em>The City and the Stars</em>.
Diaspar, with its past, and even to some extent its future, stored in the memory banks of the central computer, has existed with its determined social structure for over a billion years.
But the original planners of the city realized that perfect order was too much for man to bear:

<blockquote>
&ldquo;Stability, however, is not enough.
It leads too easily to stagnation, and thence to decadence.
The designers of the city took elaborate steps to avoid this, &hellip;
I, Khedron the Jester, am part of that plan.
A very small part, perhaps.
I like to think otherwise, but I can never be sure &hellip;  Let us say that I introduce calculated amounts of disorder into the city.&rdquo;
\footnote{
    A. C. Clarke, <em>The City and the Stars</em> (Harcourt, Brace and Co., New York, 1953). pp 47&endash;53.
}
</blockquote>


But our present situation confronts us with something more than a simple dichotomy between order and disorder, as suggested in both of the following passages, one from L. L. Whyte and one from Erwin Schrodinger:


<blockquote>
In his long pursuit of order in nature, the scientist has turned a corner.
He is now after <em>order and disorder</em> without prejudice, having discovered
that complexity usually involves both,
\footnote{
    L. L. Whyte, &ldquo;Atomism, Structure, and Form,&rdquo; in Structure in Art and in Science, ed. G. Kepes (G. Braziller, New York, 1965) p. 20.
}

The judicious elimination of detail, which the statistical system has
taught us, has brought about a complete transformation of our knowledge
of the heavens. ... It is manifest on all sides that this statistical method
is a dominant feature of our epoch, an important instrument of progress in almost every sphere of public life.
\footnote{
    E. Schrodinger, <em>Science and Human Temperament</em>, trans. J. Murphy and W. H. Johnston (W. W. Norton, Inc., New York), p. 128.
}
</blockquote>


Although the use of random methods in physics and biology at the end of the last century originally assumed that one was dealing with areas that could not be treated exactly, but where exact laws did exist, a subtle change of view has come about, so that now random elements are seen as having a validity of their own.
Both Whytc and Schrodinger see the current situation as something more than a choice between two possibilities. Whyte thinks both are essential for something he calls &ldquo;complexity.&rdquo;
But I prefer Schrodinger&#39;s suggestion that the two are not necessarily opposed, and that randomness can be a tool for increasing order.
Perhaps we have a situation resembling a Hegelian synthesis, combining two themes which had been considered in direct opposition.


Finally I note an important twentieth century reaction to randomness: Joy.
The persistence of games of chance through the ages shows that men have always derived some pleasure from randomness;
    they are important in Clarke&#39;s Diaspar, for example:


<blockquote>
    In a world of order and stability, which in its broad outlines had not changed for a bilUon years, it was perhaps not surprising to find an absorbing interest in games of chance.
    Humanity had always been fascinated by the mystery of the falling dice, the turn of a card, the spin of the pointer &hellip; however, the purely intellectual fascination of chance remained to seduce the most sophisticated minds.
    Machines that behaved in a purely random way&emdash;events whose outcome could never be predicted, no matter how much information one had — from these philosopher and gambler could derive equal enjoyment.
</blockquote>


But the present joy exceeds even this.
Contemporary man often feels excitement in the presence of randomness, welcoming it in a way that would have seemed very strange in the immediate past.
In some areas (literature, perhaps) this excitement still seems not quite proper, so it is not expressed openly.
But in other places randomness is clearly acknowledged.
We noted that the artist is particularly willing to admit the use of randomness, so it is not surprising to see an artist, Ben Shahn, admitting his pleasure: &ldquo;I love chaos.
It is a mysterious, unknown road with unexpected turnings. It is the way out.
It is freedom, man&#39;s best hope.&rdquo;
\footnote{
    Quoted in <em>Industrial Design</em> 13, 16 (1966).
}





